{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project PICOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the files\n",
    "camera_df = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Cameras.shp\")\n",
    "rivieres = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Rivieres.shp\")\n",
    "roads = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Reseau_Routier.shp\")\n",
    "railroad = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Reseau_Ferroviaire.shp\")\n",
    "slope = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Pente.shp\")\n",
    "landcover = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Type_Couverture.shp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the camera dataframe\n",
    "camera_df.to_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\points.shp\", )\n",
    "camera_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the projection is the right one\n",
    "camera_df = camera_df.to_crs('EPSG:26918')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create buffers of 500m, 1km and 2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create buffers for each cameras\n",
    "buffered_geometries_500m = camera_df.geometry.apply(lambda geom: geom.buffer(500))\n",
    "buffered_geometries_1km = camera_df.geometry.apply(lambda geom: geom.buffer(1000))\n",
    "buffered_geometries_2km = camera_df.geometry.apply(lambda geom: geom.buffer(2000))\n",
    "\n",
    "# Create GeoDataFrames for each buffer\n",
    "buffered_camera_df_500m = gpd.GeoDataFrame(geometry=buffered_geometries_500m, crs=camera_df.crs)\n",
    "buffered_camera_df_1km = gpd.GeoDataFrame(geometry=buffered_geometries_1km, crs=camera_df.crs)\n",
    "buffered_camera_df_2km = gpd.GeoDataFrame(geometry=buffered_geometries_2km, crs=camera_df.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the buffers shp\n",
    "buffered_camera_df_500m.to_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\buffers_500m.shp\")\n",
    "buffered_camera_df_1km.to_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\buffers_1km.shp\")\n",
    "buffered_camera_df_2km.to_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\buffers_2km.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'id' with index values\n",
    "buffered_camera_df_1km['id'] = buffered_camera_df_1km.index\n",
    "buffered_camera_df_1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'id' with index values\n",
    "buffered_camera_df_500m['id'] = buffered_camera_df_500m.index\n",
    "buffered_camera_df_500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'id' with index values\n",
    "buffered_camera_df_2km['id'] = buffered_camera_df_2km.index\n",
    "buffered_camera_df_2km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the rivers shp projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS of rivieres: EPSG:26918\n",
      "CRS of buffered_camera_df_500m: EPSG:26918\n"
     ]
    }
   ],
   "source": [
    "print(\"CRS of rivieres:\", rivieres.crs)\n",
    "print(\"CRS of buffered_camera_df_500m:\", buffered_camera_df_500m.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rivieres.crs is None:\n",
    "    rivieres.crs = 'EPSG:26918'\n",
    "rivieres = rivieres.to_crs(buffered_camera_df_500m.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rivers buffers 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# Assuming you have a GeoDataFrame called 'rivieres'\n",
    "for selected_buffer_index in range(len(buffered_camera_df_500m)):\n",
    "    selected_buffer = buffered_camera_df_500m.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(rivieres, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    #clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=rivieres.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\rivers_buffers_500m.csv\", index=False)\n",
    "\n",
    "# Export the clipped results GeoDataFrame to a shapefile\n",
    "#clipped_results_gdf.to_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\rivers_500m.shp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rivers buffers 1km   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# Assuming you have a GeoDataFrame called 'rivieres'\n",
    "for selected_buffer_index in range(len(buffered_camera_df_1km)):\n",
    "    selected_buffer = buffered_camera_df_1km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(rivieres, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    #clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=rivieres.crs)\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\rivers_buffers_1km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rivers buffers 2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# Assuming you have a GeoDataFrame called 'rivieres'\n",
    "for selected_buffer_index in range(len(buffered_camera_df_2km)):\n",
    "    selected_buffer = buffered_camera_df_2km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(rivieres, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    #clipped_rivieres.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=rivieres.crs)\n",
    "\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\rivers_buffers_2km.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS of roads: EPSG:26918\n",
      "CRS of buffered_camera_df_500m: EPSG:26918\n"
     ]
    }
   ],
   "source": [
    "print(\"CRS of roads:\", roads.crs)\n",
    "print(\"CRS of buffered_camera_df_500m:\", buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roads.crs is None:\n",
    "    roads.crs = 'EPSG:26918'\n",
    "roads = roads.to_crs(buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roads buffers 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# Assuming you have a GeoDataFrame called 'rivieres'\n",
    "for selected_buffer_index in range(len(buffered_camera_df_500m)):\n",
    "    selected_buffer = buffered_camera_df_500m.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(roads, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    #clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=roads.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\roads_buffers_500m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the shp\n",
    "clipped_results_gdf.to_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\river_500m.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roads buffers 1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_1km)):\n",
    "    selected_buffer = buffered_camera_df_1km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(roads, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=roads.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\roads_buffers_1km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roads buffers 2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_2km)):\n",
    "    selected_buffer = buffered_camera_df_2km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(roads, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    #You can plot the result\n",
    "    #clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=roads.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\roads_buffers_2km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_1km)):\n",
    "    selected_buffer = buffered_camera_df_1km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(roads, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=roads.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\roads_buffers_1km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Railroads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS of roads: EPSG:26918\n",
      "CRS of buffered_camera_df_500m: EPSG:26918\n"
     ]
    }
   ],
   "source": [
    "print(\"CRS of roads:\", railroad.crs)\n",
    "print(\"CRS of buffered_camera_df_500m:\", buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "if railroad.crs is None:\n",
    "    railroad.crs = 'EPSG:26918'\n",
    "railroad = railroad.to_crs(buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Railroad buffer 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_500m)):\n",
    "    selected_buffer = buffered_camera_df_500m.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(railroad, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=railroad.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\railroad_buffers_500m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Railroad buffers 1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_1km)):\n",
    "    selected_buffer = buffered_camera_df_1km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(railroad, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=railroad.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\railroad_buffers_1km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Railroad buffers 2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Buffer Index\", \"Clipped Length\"])\n",
    "\n",
    "# Create an empty GeoDataFrame to store the clipped results\n",
    "clipped_results_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_2km)):\n",
    "    selected_buffer = buffered_camera_df_2km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    clipped_shp = gpd.overlay(railroad, selected_buffer, how='intersection')\n",
    "    clipped_length = clipped_shp.length.sum()\n",
    "    print(f\"Buffer Index {selected_buffer_index}: Clipped Length = {clipped_length}\")\n",
    "    clipped_shp.plot()\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\"Buffer Index\": [selected_buffer_index], \"Clipped Length\": [clipped_length]})], ignore_index=True)\n",
    "    clipped_results_gdf = gpd.GeoDataFrame(pd.concat([clipped_results_gdf, clipped_shp]), crs=railroad.crs)\n",
    "\n",
    "# Export the results DataFrame to a CSV file\n",
    "results_df.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\railroad_buffers_2km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS of roads: EPSG:26918\n",
      "CRS of buffered_camera_df_500m: EPSG:26918\n"
     ]
    }
   ],
   "source": [
    "print(\"CRS of roads:\", slope.crs)\n",
    "print(\"CRS of buffered_camera_df_500m:\", buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "if slope.crs is None:\n",
    "    slope.crs = 'EPSG:26918'\n",
    "slope = slope.to_crs(buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope buffer 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming buffered_camera_df_500m and slope are predefined GeoDataFrames\n",
    "\n",
    "# Create an empty DataFrame for storing aggregated results\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_500m)):\n",
    "    # Select a single buffer zone\n",
    "    selected_buffer = buffered_camera_df_500m.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "\n",
    "    # Calculate the intersection\n",
    "    clipped_shp = gpd.overlay(slope, selected_buffer, how='intersection')\n",
    "\n",
    "    # Check if the required columns ('id', 'CL_PENT', 'SUPERFICIE') exist in clipped_shp\n",
    "    if 'id' in clipped_shp.columns and 'CL_PENT' in clipped_shp.columns and 'SUPERFICIE' in clipped_shp.columns:\n",
    "        # Group the data by 'id' and 'CL_PENT' and calculate the sum of 'SUPERFICIE'\n",
    "        grouped_data = clipped_shp.groupby(['id', 'CL_PENT'])['SUPERFICIE'].sum().reset_index()\n",
    "        \n",
    "        # Append the grouped data to the aggregated_results DataFrame\n",
    "        aggregated_results = pd.concat([aggregated_results, grouped_data], ignore_index=True)\n",
    "\n",
    "# Optional: You can group and sum again in case there are overlapping ids and CL_PENTs across different buffer zones\n",
    "        \n",
    "# Export the grouped data to a CSV file\n",
    "aggregated_results.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\slope_buffers_500m.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the grouped data to a CSV file\n",
    "grouped_data.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\slope_buffers_500m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope buffers 1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_1km)):\n",
    "    selected_buffer = buffered_camera_df_1km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    # Calculate the intersection\n",
    "    clipped_shp = gpd.overlay(slope, selected_buffer, how='intersection')\n",
    "\n",
    "    if 'id' in clipped_shp.columns and 'CL_PENT' in clipped_shp.columns and 'SUPERFICIE' in clipped_shp.columns:\n",
    "        grouped_data = clipped_shp.groupby(['id', 'CL_PENT'])['SUPERFICIE'].sum().reset_index()\n",
    "        \n",
    "        # Append the grouped data to the aggregated_results DataFrame\n",
    "        aggregated_results = pd.concat([aggregated_results, grouped_data], ignore_index=True)\n",
    "        \n",
    "# Export the grouped data to a CSV file\n",
    "aggregated_results.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\slope_buffers_1km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope buffers 2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_2km)):\n",
    "    selected_buffer = buffered_camera_df_2km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    # Calculate the intersection\n",
    "    clipped_shp = gpd.overlay(slope, selected_buffer, how='intersection')\n",
    "\n",
    "    if 'id' in clipped_shp.columns and 'CL_PENT' in clipped_shp.columns and 'SUPERFICIE' in clipped_shp.columns:\n",
    "        grouped_data = clipped_shp.groupby(['id', 'CL_PENT'])['SUPERFICIE'].sum().reset_index()\n",
    "        \n",
    "        # Append the grouped data to the aggregated_results DataFrame\n",
    "        aggregated_results = pd.concat([aggregated_results, grouped_data], ignore_index=True)\n",
    "        \n",
    "# Export the grouped data to a CSV file\n",
    "aggregated_results.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\slope_buffers_2km.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landcover type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS of roads: EPSG:26918\n",
      "CRS of buffered_camera_df_500m: EPSG:26918\n"
     ]
    }
   ],
   "source": [
    "print(\"CRS of roads:\", landcover.crs)\n",
    "print(\"CRS of buffered_camera_df_500m:\", buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "landcover.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\landcover.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip the rivers with the buffers\n",
    "clip_rivers_500m = gpd.clip(roads, buffered_camera_df_1km)\n",
    "clip_rivers_500m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landcover buffers 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_500m)):\n",
    "    selected_buffer = buffered_camera_df_500m.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    # Calculate the intersection\n",
    "    clipped_shp = gpd.overlay(landcover, selected_buffer, how='intersection')\n",
    "\n",
    "    if 'id' in clipped_shp.columns and 'CL_PENT' in clipped_shp.columns and 'SUPERFICIE' in clipped_shp.columns:\n",
    "        grouped_data = clipped_shp.groupby(['id', 'TYPE_ECO'])['SUPERFICIE'].sum().reset_index()\n",
    "        \n",
    "        # Append the grouped data to the aggregated_results DataFrame\n",
    "        aggregated_results = pd.concat([aggregated_results, grouped_data], ignore_index=True)\n",
    "        \n",
    "# Export the grouped data to a CSV file\n",
    "aggregated_results.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\landcover_buffers_500m.csv\", index=False)\n",
    "aggregated_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landcover buffers 1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_1km)):\n",
    "    selected_buffer = buffered_camera_df_1km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    # Calculate the intersection\n",
    "    clipped_shp = gpd.overlay(landcover, selected_buffer, how='intersection')\n",
    "\n",
    "    if 'id' in clipped_shp.columns and 'CL_PENT' in clipped_shp.columns and 'SUPERFICIE' in clipped_shp.columns:\n",
    "        grouped_data = clipped_shp.groupby(['id', 'TYPE_ECO'])['SUPERFICIE'].sum().reset_index()\n",
    "        \n",
    "        # Append the grouped data to the aggregated_results DataFrame\n",
    "        aggregated_results = pd.concat([aggregated_results, grouped_data], ignore_index=True)\n",
    "        \n",
    "# Export the grouped data to a CSV file\n",
    "aggregated_results.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\landcover_buffers_1km.csv\", index=False)\n",
    "aggregated_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landcover buffers 2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "for selected_buffer_index in range(len(buffered_camera_df_2km)):\n",
    "    selected_buffer = buffered_camera_df_2km.iloc[selected_buffer_index:selected_buffer_index + 1]\n",
    "    # Calculate the intersection\n",
    "    clipped_shp = gpd.overlay(landcover, selected_buffer, how='intersection')\n",
    "\n",
    "    if 'id' in clipped_shp.columns and 'CL_PENT' in clipped_shp.columns and 'SUPERFICIE' in clipped_shp.columns:\n",
    "        grouped_data = clipped_shp.groupby(['id', 'TYPE_ECO'])['SUPERFICIE'].sum().reset_index()\n",
    "        \n",
    "        # Append the grouped data to the aggregated_results DataFrame\n",
    "        aggregated_results = pd.concat([aggregated_results, grouped_data], ignore_index=True)\n",
    "        \n",
    "# Export the grouped data to a CSV file\n",
    "aggregated_results.to_csv(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\landcover_buffers_2km.csv\", index=False)\n",
    "aggregated_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Read the raster file\n",
    "raster_file = r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Utilisation_Territoire.tif\"\n",
    "raster_data = rasterio.open(raster_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading WhiteboxTools pre-compiled binary for first time use ...\n",
      "Decompressing WhiteboxTools_win_amd64.zip ...\n",
      "WhiteboxTools package directory: c:\\Users\\thier\\miniforge3\\envs\\geospatial\\Lib\\site-packages\\whitebox\n",
      "Downloading testdata ...\n"
     ]
    }
   ],
   "source": [
    "import whitebox\n",
    "wbt = whitebox.WhiteboxTools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRS of roads:\", raster_file.crs)\n",
    "print(\"CRS of buffered_camera_df_500m:\", buffered_camera_df_1km.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.clip_raster_to_polygon(\n",
    "    i=r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Utilisation_Territoire.tif\", \n",
    "    polygons=r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\buffers_500m.shp\", \n",
    "    output=r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Utilisation_Territoire_clip.tif\", \n",
    "    maintain_dimensions=False   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\whitebox_tools.exe --run=\"RasterToVectorPolygons\" --input='C:\\Users\\thier\\Downloads\\Projet\\Projet\\Utilisation_Territoire.tif' --output='C:\\Users\\thier\\Downloads\\Projet\\Projet\\utilisation_territoire.shp' -v --compress_rasters=False\n",
      "\n",
      "*************************************\n",
      "* Welcome to RasterToVectorPolygons *\n",
      "* Powered by WhiteboxTools          *\n",
      "* www.whiteboxgeo.com               *\n",
      "*************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Clumping polygons: 0%\n",
      "Clumping polygons: 1%\n",
      "Clumping polygons: 2%\n",
      "Clumping polygons: 3%\n",
      "Clumping polygons: 4%\n",
      "Clumping polygons: 5%\n",
      "Clumping polygons: 6%\n",
      "Clumping polygons: 7%\n",
      "Clumping polygons: 8%\n",
      "Clumping polygons: 9%\n",
      "Clumping polygons: 10%\n",
      "Clumping polygons: 11%\n",
      "Clumping polygons: 12%\n",
      "Clumping polygons: 13%\n",
      "Clumping polygons: 14%\n",
      "Clumping polygons: 15%\n",
      "Clumping polygons: 16%\n",
      "Clumping polygons: 17%\n",
      "Clumping polygons: 18%\n",
      "Clumping polygons: 19%\n",
      "Clumping polygons: 20%\n",
      "Clumping polygons: 21%\n",
      "Clumping polygons: 22%\n",
      "Clumping polygons: 23%\n",
      "Clumping polygons: 24%\n",
      "Clumping polygons: 25%\n",
      "Clumping polygons: 26%\n",
      "Clumping polygons: 27%\n",
      "Clumping polygons: 28%\n",
      "Clumping polygons: 29%\n",
      "Clumping polygons: 30%\n",
      "Clumping polygons: 31%\n",
      "Clumping polygons: 32%\n",
      "Clumping polygons: 33%\n",
      "Clumping polygons: 34%\n",
      "Clumping polygons: 35%\n",
      "Clumping polygons: 36%\n",
      "Clumping polygons: 37%\n",
      "Clumping polygons: 38%\n",
      "Clumping polygons: 39%\n",
      "Clumping polygons: 40%\n",
      "Clumping polygons: 41%\n",
      "Clumping polygons: 42%\n",
      "Clumping polygons: 43%\n",
      "Clumping polygons: 44%\n",
      "Clumping polygons: 45%\n",
      "Clumping polygons: 46%\n",
      "Clumping polygons: 47%\n",
      "Clumping polygons: 48%\n",
      "Clumping polygons: 49%\n",
      "Clumping polygons: 50%\n",
      "Clumping polygons: 51%\n",
      "Clumping polygons: 52%\n",
      "Clumping polygons: 53%\n",
      "Clumping polygons: 54%\n",
      "Clumping polygons: 55%\n",
      "Clumping polygons: 56%\n",
      "Clumping polygons: 57%\n",
      "Clumping polygons: 58%\n",
      "Clumping polygons: 59%\n",
      "Clumping polygons: 60%\n",
      "Clumping polygons: 61%\n",
      "Clumping polygons: 62%\n",
      "Clumping polygons: 63%\n",
      "Clumping polygons: 64%\n",
      "Clumping polygons: 65%\n",
      "Clumping polygons: 66%\n",
      "Clumping polygons: 67%\n",
      "Clumping polygons: 68%\n",
      "Clumping polygons: 69%\n",
      "Clumping polygons: 70%\n",
      "Clumping polygons: 71%\n",
      "Clumping polygons: 72%\n",
      "Clumping polygons: 73%\n",
      "Clumping polygons: 74%\n",
      "Clumping polygons: 75%\n",
      "Clumping polygons: 76%\n",
      "Clumping polygons: 77%\n",
      "Clumping polygons: 78%\n",
      "Clumping polygons: 79%\n",
      "Clumping polygons: 80%\n",
      "Clumping polygons: 81%\n",
      "Clumping polygons: 82%\n",
      "Clumping polygons: 83%\n",
      "Clumping polygons: 84%\n",
      "Clumping polygons: 85%\n",
      "Clumping polygons: 86%\n",
      "Clumping polygons: 87%\n",
      "Clumping polygons: 88%\n",
      "Clumping polygons: 89%\n",
      "Clumping polygons: 90%\n",
      "Clumping polygons: 91%\n",
      "Clumping polygons: 92%\n",
      "Clumping polygons: 93%\n",
      "Clumping polygons: 94%\n",
      "Clumping polygons: 95%\n",
      "Clumping polygons: 96%\n",
      "Clumping polygons: 97%\n",
      "Clumping polygons: 98%\n",
      "Clumping polygons: 99%\n",
      "Clumping polygons: 100%\n",
      "Finding edges: 0%\n",
      "Finding edges: 1%\n",
      "Finding edges: 2%\n",
      "Finding edges: 3%\n",
      "Finding edges: 4%\n",
      "Finding edges: 5%\n",
      "Finding edges: 6%\n",
      "Finding edges: 7%\n",
      "Finding edges: 8%\n",
      "Finding edges: 9%\n",
      "Finding edges: 10%\n",
      "Finding edges: 11%\n",
      "Finding edges: 12%\n",
      "Finding edges: 13%\n",
      "Finding edges: 14%\n",
      "Finding edges: 15%\n",
      "Finding edges: 16%\n",
      "Finding edges: 17%\n",
      "Finding edges: 18%\n",
      "Finding edges: 19%\n",
      "Finding edges: 20%\n",
      "Finding edges: 21%\n",
      "Finding edges: 22%\n",
      "Finding edges: 23%\n",
      "Finding edges: 24%\n",
      "Finding edges: 25%\n",
      "Finding edges: 26%\n",
      "Finding edges: 27%\n",
      "Finding edges: 28%\n",
      "Finding edges: 29%\n",
      "Finding edges: 30%\n",
      "Finding edges: 31%\n",
      "Finding edges: 32%\n",
      "Finding edges: 33%\n",
      "Finding edges: 34%\n",
      "Finding edges: 35%\n",
      "Finding edges: 36%\n",
      "Finding edges: 37%\n",
      "Finding edges: 38%\n",
      "Finding edges: 39%\n",
      "Finding edges: 40%\n",
      "Finding edges: 41%\n",
      "Finding edges: 42%\n",
      "Finding edges: 43%\n",
      "Finding edges: 44%\n",
      "Finding edges: 45%\n",
      "Finding edges: 46%\n",
      "Finding edges: 47%\n",
      "Finding edges: 48%\n",
      "Finding edges: 49%\n",
      "Finding edges: 50%\n",
      "Finding edges: 51%\n",
      "Finding edges: 52%\n",
      "Finding edges: 53%\n",
      "Finding edges: 54%\n",
      "Finding edges: 55%\n",
      "Finding edges: 56%\n",
      "Finding edges: 57%\n",
      "Finding edges: 58%\n",
      "Finding edges: 59%\n",
      "Finding edges: 60%\n",
      "Finding edges: 61%\n",
      "Finding edges: 62%\n",
      "Finding edges: 63%\n",
      "Finding edges: 64%\n",
      "Finding edges: 65%\n",
      "Finding edges: 66%\n",
      "Finding edges: 67%\n",
      "Finding edges: 68%\n",
      "Finding edges: 69%\n",
      "Finding edges: 70%\n",
      "Finding edges: 71%\n",
      "Finding edges: 72%\n",
      "Finding edges: 73%\n",
      "Finding edges: 74%\n",
      "Finding edges: 75%\n",
      "Finding edges: 76%\n",
      "Finding edges: 77%\n",
      "Finding edges: 78%\n",
      "Finding edges: 79%\n",
      "Finding edges: 80%\n",
      "Finding edges: 81%\n",
      "Finding edges: 82%\n",
      "Finding edges: 83%\n",
      "Finding edges: 84%\n",
      "Finding edges: 85%\n",
      "Finding edges: 86%\n",
      "Finding edges: 87%\n",
      "Finding edges: 88%\n",
      "Finding edges: 89%\n",
      "Finding edges: 90%\n",
      "Finding edges: 91%\n",
      "Finding edges: 92%\n",
      "Finding edges: 93%\n",
      "Finding edges: 94%\n",
      "Finding edges: 95%\n",
      "Finding edges: 96%\n",
      "Finding edges: 97%\n",
      "Finding edges: 98%\n",
      "Finding edges: 99%\n",
      "Finding edges: 100%\n",
      "Tracing polygons: 0%\n",
      "Tracing polygons: 1%\n",
      "Tracing polygons: 2%\n",
      "Tracing polygons: 3%\n",
      "Tracing polygons: 4%\n",
      "Tracing polygons: 5%\n",
      "Tracing polygons: 6%\n",
      "Tracing polygons: 7%\n",
      "Tracing polygons: 8%\n",
      "Tracing polygons: 9%\n",
      "Tracing polygons: 10%\n",
      "Tracing polygons: 11%\n",
      "Tracing polygons: 12%\n",
      "Tracing polygons: 13%\n",
      "Tracing polygons: 14%\n",
      "Tracing polygons: 15%\n",
      "Tracing polygons: 16%\n",
      "Tracing polygons: 17%\n",
      "Tracing polygons: 18%\n",
      "Tracing polygons: 19%\n",
      "Tracing polygons: 20%\n",
      "Tracing polygons: 21%\n",
      "Tracing polygons: 22%\n",
      "Tracing polygons: 23%\n",
      "Tracing polygons: 24%\n",
      "Tracing polygons: 25%\n",
      "Tracing polygons: 26%\n",
      "Tracing polygons: 27%\n",
      "Tracing polygons: 28%\n",
      "Tracing polygons: 29%\n",
      "Tracing polygons: 30%\n",
      "Tracing polygons: 31%\n",
      "Tracing polygons: 32%\n",
      "Tracing polygons: 33%\n",
      "Tracing polygons: 34%\n",
      "Tracing polygons: 35%\n",
      "Tracing polygons: 36%\n",
      "Tracing polygons: 37%\n",
      "Tracing polygons: 38%\n",
      "Tracing polygons: 39%\n",
      "Tracing polygons: 40%\n",
      "Tracing polygons: 41%\n",
      "Tracing polygons: 42%\n",
      "Tracing polygons: 43%\n",
      "Tracing polygons: 44%\n",
      "Tracing polygons: 45%\n",
      "Tracing polygons: 46%\n",
      "Tracing polygons: 47%\n",
      "Tracing polygons: 48%\n",
      "Tracing polygons: 49%\n",
      "Tracing polygons: 50%\n",
      "Tracing polygons: 51%\n",
      "Tracing polygons: 52%\n",
      "Tracing polygons: 53%\n",
      "Tracing polygons: 54%\n",
      "Tracing polygons: 55%\n",
      "Tracing polygons: 56%\n",
      "Tracing polygons: 57%\n",
      "Tracing polygons: 58%\n",
      "Tracing polygons: 59%\n",
      "Tracing polygons: 60%\n",
      "Tracing polygons: 61%\n",
      "Tracing polygons: 62%\n",
      "Tracing polygons: 63%\n",
      "Tracing polygons: 64%\n",
      "Tracing polygons: 65%\n",
      "Tracing polygons: 66%\n",
      "Tracing polygons: 67%\n",
      "Tracing polygons: 68%\n",
      "Tracing polygons: 69%\n",
      "Tracing polygons: 70%\n",
      "Tracing polygons: 71%\n",
      "Tracing polygons: 72%\n",
      "Tracing polygons: 73%\n",
      "Tracing polygons: 74%\n",
      "Tracing polygons: 75%\n",
      "Tracing polygons: 76%\n",
      "Tracing polygons: 77%\n",
      "Tracing polygons: 78%\n",
      "Tracing polygons: 79%\n",
      "Tracing polygons: 80%\n",
      "Tracing polygons: 81%\n",
      "Tracing polygons: 82%\n",
      "Tracing polygons: 83%\n",
      "Tracing polygons: 84%\n",
      "Tracing polygons: 85%\n",
      "Tracing polygons: 86%\n",
      "Tracing polygons: 87%\n",
      "Tracing polygons: 88%\n",
      "Tracing polygons: 89%\n",
      "Tracing polygons: 90%\n",
      "Tracing polygons: 91%\n",
      "Tracing polygons: 92%\n",
      "Tracing polygons: 93%\n",
      "Tracing polygons: 94%\n",
      "Tracing polygons: 95%\n",
      "Tracing polygons: 96%\n",
      "Tracing polygons: 97%\n",
      "Tracing polygons: 98%\n",
      "Tracing polygons: 99%\n",
      "Tracing polygons: 100%\n",
      "Creating geometries: 0%\n",
      "Creating geometries: 1%\n",
      "Creating geometries: 2%\n",
      "Creating geometries: 3%\n",
      "Creating geometries: 4%\n",
      "Creating geometries: 5%\n",
      "Creating geometries: 6%\n",
      "Creating geometries: 7%\n",
      "Creating geometries: 8%\n",
      "Creating geometries: 9%\n",
      "Creating geometries: 10%\n",
      "Creating geometries: 11%\n",
      "Creating geometries: 12%\n",
      "Creating geometries: 13%\n",
      "Creating geometries: 14%\n",
      "Creating geometries: 15%\n",
      "Creating geometries: 16%\n",
      "Creating geometries: 17%\n",
      "Creating geometries: 18%\n",
      "Creating geometries: 19%\n",
      "Creating geometries: 20%\n",
      "Creating geometries: 21%\n",
      "Creating geometries: 22%\n",
      "Creating geometries: 23%\n",
      "Creating geometries: 24%\n",
      "Creating geometries: 25%\n",
      "Creating geometries: 26%\n",
      "Creating geometries: 27%\n",
      "Creating geometries: 28%\n",
      "Creating geometries: 29%\n",
      "Creating geometries: 30%\n",
      "Creating geometries: 31%\n",
      "Creating geometries: 32%\n",
      "Creating geometries: 33%\n",
      "Creating geometries: 34%\n",
      "Creating geometries: 35%\n",
      "Creating geometries: 36%\n",
      "Creating geometries: 37%\n",
      "Creating geometries: 38%\n",
      "Creating geometries: 39%\n",
      "Creating geometries: 40%\n",
      "Creating geometries: 41%\n",
      "Creating geometries: 42%\n",
      "Creating geometries: 43%\n",
      "Creating geometries: 44%\n",
      "Creating geometries: 45%\n",
      "Creating geometries: 46%\n",
      "Creating geometries: 47%\n",
      "Creating geometries: 48%\n",
      "Creating geometries: 49%\n",
      "Creating geometries: 50%\n",
      "Creating geometries: 51%\n",
      "Creating geometries: 52%\n",
      "Creating geometries: 53%\n",
      "Creating geometries: 54%\n",
      "Creating geometries: 55%\n",
      "Creating geometries: 56%\n",
      "Creating geometries: 57%\n",
      "Creating geometries: 58%\n",
      "Creating geometries: 59%\n",
      "Creating geometries: 60%\n",
      "Creating geometries: 61%\n",
      "Creating geometries: 62%\n",
      "Creating geometries: 63%\n",
      "Creating geometries: 64%\n",
      "Creating geometries: 65%\n",
      "Creating geometries: 66%\n",
      "Creating geometries: 67%\n",
      "Creating geometries: 68%\n",
      "Creating geometries: 69%\n",
      "Creating geometries: 70%\n",
      "Creating geometries: 71%\n",
      "Creating geometries: 72%\n",
      "Creating geometries: 73%\n",
      "Creating geometries: 74%\n",
      "Creating geometries: 75%\n",
      "Creating geometries: 76%\n",
      "Creating geometries: 77%\n",
      "Creating geometries: 78%\n",
      "Creating geometries: 79%\n",
      "Creating geometries: 80%\n",
      "Creating geometries: 81%\n",
      "Creating geometries: 82%\n",
      "Creating geometries: 83%\n",
      "Creating geometries: 84%\n",
      "Creating geometries: 85%\n",
      "Creating geometries: 86%\n",
      "Creating geometries: 87%\n",
      "Creating geometries: 88%\n",
      "Creating geometries: 89%\n",
      "Creating geometries: 90%\n",
      "Creating geometries: 91%\n",
      "Creating geometries: 92%\n",
      "Creating geometries: 93%\n",
      "Creating geometries: 94%\n",
      "Creating geometries: 95%\n",
      "Creating geometries: 96%\n",
      "Creating geometries: 97%\n",
      "Creating geometries: 98%\n",
      "Creating geometries: 99%\n",
      "Creating geometries: 100%\n",
      "Saving data...\n",
      "Output file written\n",
      "Elapsed Time (excluding I/O): 1min 3.96s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbt.raster_to_vector_polygons(\n",
    "    i=r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Utilisation_Territoire.tif\", \n",
    "    output=r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\utilisation_territoire.shp\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POLYGON ((666990.202 5160834.670, 666990.202 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>619.0</td>\n",
       "      <td>POLYGON ((667060.327 5160763.815, 667060.327 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>565.0</td>\n",
       "      <td>POLYGON ((666896.703 5160752.005, 666896.703 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>595.0</td>\n",
       "      <td>MULTIPOLYGON (((667188.889 5160633.912, 667188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>595.0</td>\n",
       "      <td>POLYGON ((666744.766 5160610.293, 666744.766 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42028</th>\n",
       "      <td>42029</td>\n",
       "      <td>7021.0</td>\n",
       "      <td>MULTIPOLYGON (((672050.863 5127142.664, 672050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42029</th>\n",
       "      <td>42030</td>\n",
       "      <td>7529.0</td>\n",
       "      <td>POLYGON ((671898.927 5127130.855, 671898.927 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42030</th>\n",
       "      <td>42031</td>\n",
       "      <td>4055.0</td>\n",
       "      <td>MULTIPOLYGON (((671922.302 5127119.046, 671922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42031</th>\n",
       "      <td>42032</td>\n",
       "      <td>7021.0</td>\n",
       "      <td>MULTIPOLYGON (((672004.114 5127107.237, 672004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42032</th>\n",
       "      <td>42033</td>\n",
       "      <td>7055.0</td>\n",
       "      <td>POLYGON ((671945.677 5127095.427, 671945.677 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42033 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FID   VALUE                                           geometry\n",
       "0          1   574.0  POLYGON ((666990.202 5160834.670, 666990.202 5...\n",
       "1          2   619.0  POLYGON ((667060.327 5160763.815, 667060.327 5...\n",
       "2          3   565.0  POLYGON ((666896.703 5160752.005, 666896.703 5...\n",
       "3          4   595.0  MULTIPOLYGON (((667188.889 5160633.912, 667188...\n",
       "4          5   595.0  POLYGON ((666744.766 5160610.293, 666744.766 5...\n",
       "...      ...     ...                                                ...\n",
       "42028  42029  7021.0  MULTIPOLYGON (((672050.863 5127142.664, 672050...\n",
       "42029  42030  7529.0  POLYGON ((671898.927 5127130.855, 671898.927 5...\n",
       "42030  42031  4055.0  MULTIPOLYGON (((671922.302 5127119.046, 671922...\n",
       "42031  42032  7021.0  MULTIPOLYGON (((672004.114 5127107.237, 672004...\n",
       "42032  42033  7055.0  POLYGON ((671945.677 5127095.427, 671945.677 5...\n",
       "\n",
       "[42033 rows x 3 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil = gpd.read_file(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\utilisation_territoire.shp\")\n",
    "soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Raster Attribute Table found.\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "# Open the raster dataset\n",
    "dataset = gdal.Open(r\"C:\\Users\\thier\\Downloads\\Projet\\Projet\\Utilisation_Territoire.tif\", gdal.GA_ReadOnly)\n",
    "\n",
    "# Assuming the RAT is associated with the first band\n",
    "band = dataset.GetRasterBand(1)\n",
    "\n",
    "# Fetch the RAT\n",
    "rat = band.GetDefaultRAT()\n",
    "\n",
    "# Check if the RAT exists\n",
    "if rat is not None:\n",
    "    # Get the number of rows in the RAT\n",
    "    ratRowCount = rat.GetRowCount()\n",
    "\n",
    "    # Loop through each row and read values\n",
    "    for row in range(ratRowCount):\n",
    "        # Replace 'Field_Name' with the name of the field you want to read\n",
    "        value = rat.GetValueAsString(row, rat.GetColOfUsage(gdal.GFU_Name))\n",
    "        print(f\"Row {row}: {value}\")\n",
    "else:\n",
    "    print(\"No Raster Attribute Table found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
